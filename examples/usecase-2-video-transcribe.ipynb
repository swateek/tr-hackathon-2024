{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UseCase 2 - Video Transcribe\n",
    "\n",
    "**References**\n",
    "\n",
    "1. [Transribe - Python](https://docs.aws.amazon.com/code-library/latest/ug/python_3_transcribe_code_examples.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import time\n",
    "import boto3\n",
    "import json\n",
    "import logging\n",
    "import urllib.request\n",
    "import random\n",
    "from botocore.exceptions import ClientError\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(levelname)s - %(asctime)s - %(message)s\", level=logging.ERROR\n",
    ")\n",
    "\n",
    "logger = logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILENAME=\".config.ini\"\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(CONFIG_FILENAME)\n",
    "\n",
    "def get_value_by_section_and_key(section, key):\n",
    "        \"\"\"get_value_by_section_and_key\"\"\"\n",
    "        return config.get(section, key)\n",
    "\n",
    "def get_all_details_of_section(section) -> dict:\n",
    "    \"\"\"get_all_details_of_section\"\"\"\n",
    "    return dict(config.items(section))\n",
    "\n",
    "\n",
    "default_cfgs = get_all_details_of_section(\"DEFAULT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create boto3 client - BEDROCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribe_client = boto3.client(\n",
    "    'transcribe',\n",
    "    region_name=default_cfgs.get(\"aws_default_region\", \"\"),\n",
    "    aws_access_key_id=default_cfgs.get(\"aws_access_key_id\", \"\"),\n",
    "    aws_secret_access_key=default_cfgs.get(\"aws_secret_access_key\", \"\"),\n",
    "    aws_session_token=default_cfgs.get(\"aws_session_token\", \"\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_file(job_name, file_uri, transcribe_client):\n",
    "    transcribe_client.start_transcription_job(\n",
    "        TranscriptionJobName=job_name,\n",
    "        Media={\"MediaFileUri\": file_uri},\n",
    "        MediaFormat=\"mp4\",\n",
    "        LanguageCode=\"en-US\",\n",
    "    )\n",
    "\n",
    "    max_tries = 60\n",
    "    while max_tries > 0:\n",
    "        transcript_url = \"\"\n",
    "        max_tries -= 1\n",
    "        job = transcribe_client.get_transcription_job(TranscriptionJobName=job_name)\n",
    "        job_status = job[\"TranscriptionJob\"][\"TranscriptionJobStatus\"]\n",
    "        if job_status in [\"COMPLETED\", \"FAILED\"]:\n",
    "            print(f\"Job {job_name} is {job_status}.\")\n",
    "            if job_status == \"COMPLETED\":\n",
    "                print(\n",
    "                    f\"Download the transcript from\\n\"\n",
    "                    f\"\\t{job['TranscriptionJob']['Transcript']['TranscriptFileUri']}.\"\n",
    "                )\n",
    "                transcript_url = job['TranscriptionJob']['Transcript']['TranscriptFileUri']\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Waiting for {job_name}. Current status is {job_status}.\")\n",
    "        time.sleep(10)\n",
    "\n",
    "    text = \"\"\n",
    "    if(len(transcript_url) > 0):\n",
    "        response = urllib.request.urlopen(transcript_url)\n",
    "        data = json.loads(response.read())\n",
    "        \n",
    "        # Extract the transcript text\n",
    "        text = data['results']['transcripts'][0]['transcript']\n",
    "\n",
    "    return text\n",
    "\n",
    "BUCKET_NAME=\"tr-hackathon\"\n",
    "MEDIAFILE=\"usecase-exp/nirmala-sitharaman-fm-parliament.mp4\"\n",
    "file_uri = \"s3://\" + BUCKET_NAME + \"/\" + MEDIAFILE\n",
    "job_id = \"Transcribe-job-\"+str(random.randint(9, 10054))\n",
    "transcibed_text = transcribe_file(job_id, file_uri, transcribe_client)\n",
    "\n",
    "transcibed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate Text\n",
    "\n",
    "1. [List of Supported Lanugages](https://docs.aws.amazon.com/translate/latest/dg/what-is-languages.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_client = boto3.client(\n",
    "    'translate',\n",
    "    region_name=default_cfgs.get(\"aws_default_region\", \"\"),\n",
    "    aws_access_key_id=default_cfgs.get(\"aws_access_key_id\", \"\"),\n",
    "    aws_secret_access_key=default_cfgs.get(\"aws_secret_access_key\", \"\"),\n",
    "    aws_session_token=default_cfgs.get(\"aws_session_token\", \"\")\n",
    ")\n",
    "\n",
    "\n",
    "transalated_text = translate_client.translate_text(Text=transcibed_text, \n",
    "            SourceLanguageCode=\"en\", TargetLanguageCode=\"fr\")\n",
    "print('TranslatedText: ' + transalated_text.get('TranslatedText'))\n",
    "print('SourceLanguageCode: ' + transalated_text.get('SourceLanguageCode'))\n",
    "print('TargetLanguageCode: ' + transalated_text.get('TargetLanguageCode'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_text_into_chunks(text: str, max_length: int = 4900) -> List[str]:\n",
    "#     \"\"\"\n",
    "#     Split text into chunks smaller than Amazon Comprehend's limit\n",
    "#     \"\"\"\n",
    "#     words = text.split()\n",
    "#     chunks = []\n",
    "#     current_chunk = []\n",
    "#     current_length = 0\n",
    "    \n",
    "#     for word in words:\n",
    "#         # Add space before word (except for first word in chunk)\n",
    "#         word_length = len(word) + (1 if current_chunk else 0)\n",
    "        \n",
    "#         if current_length + word_length <= max_length:\n",
    "#             current_chunk.append(word)\n",
    "#             current_length += word_length\n",
    "#         else:\n",
    "#             # Save current chunk and start new one\n",
    "#             chunks.append(' '.join(current_chunk))\n",
    "#             current_chunk = [word]\n",
    "#             current_length = len(word)\n",
    "    \n",
    "#     # Add the last chunk\n",
    "#     if current_chunk:\n",
    "#         chunks.append(' '.join(current_chunk))\n",
    "    \n",
    "#     return chunks\n",
    "\n",
    "# def analyze_sentiment(text: str) -> Dict:\n",
    "#     \"\"\"\n",
    "#     Analyze sentiment of text chunk\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         comprehend_client = boto3.client(\n",
    "#             'comprehend',\n",
    "#             region_name=default_cfgs.get(\"aws_default_region\", \"\"),\n",
    "#             aws_access_key_id=default_cfgs.get(\"aws_access_key_id\", \"\"),\n",
    "#             aws_secret_access_key=default_cfgs.get(\"aws_secret_access_key\", \"\"),\n",
    "#             aws_session_token=default_cfgs.get(\"aws_session_token\", \"\")\n",
    "#         )\n",
    "#         response = comprehend_client.detect_sentiment(\n",
    "#             Text=text,\n",
    "#             LanguageCode='en'\n",
    "#         )\n",
    "#         print(response)\n",
    "#         return {\n",
    "#             'sentiment': response['Sentiment'],\n",
    "#             'scores': response['SentimentScore']\n",
    "#         }\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error analyzing sentiment: {str(e)}\")\n",
    "#         return None\n",
    "\n",
    "# def get_key_phrases(text: str) -> List[str]:\n",
    "#     \"\"\"\n",
    "#     Extract key phrases from text chunk\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         comprehend_client = boto3.client(\n",
    "#             'comprehend',\n",
    "#             region_name=default_cfgs.get(\"aws_default_region\", \"\"),\n",
    "#             aws_access_key_id=default_cfgs.get(\"aws_access_key_id\", \"\"),\n",
    "#             aws_secret_access_key=default_cfgs.get(\"aws_secret_access_key\", \"\"),\n",
    "#             aws_session_token=default_cfgs.get(\"aws_session_token\", \"\")\n",
    "#         )\n",
    "#         response = comprehend_client.detect_key_phrases(\n",
    "#             Text=text,\n",
    "#             LanguageCode='en'\n",
    "#         )\n",
    "#         return [phrase['Text'] for phrase in response['KeyPhrases']]\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error extracting key phrases: {str(e)}\")\n",
    "#         return []\n",
    "\n",
    "# def summarize_text(text: str) -> Dict:\n",
    "#     \"\"\"\n",
    "#     Summarize text while handling size limitations\n",
    "#     \"\"\"\n",
    "#     # Split text into chunks\n",
    "#     chunks = split_text_into_chunks(text)\n",
    "    \n",
    "#     # Initialize results\n",
    "#     all_sentiments = []\n",
    "#     all_key_phrases = []\n",
    "    \n",
    "#     # Process each chunk\n",
    "#     for i, chunk in enumerate(chunks):\n",
    "#         print(f\"Processing chunk {i+1}/{len(chunks)}\")\n",
    "        \n",
    "#         # Analyze sentiment\n",
    "#         sentiment_result = analyze_sentiment(chunk)\n",
    "#         if sentiment_result:\n",
    "#             all_sentiments.append(sentiment_result)\n",
    "            \n",
    "#         # Get key phrases\n",
    "#         key_phrases = get_key_phrases(chunk)\n",
    "#         all_key_phrases.extend(key_phrases)\n",
    "        \n",
    "#         # Add small delay to avoid rate limiting\n",
    "#         time.sleep(0.1)\n",
    "    \n",
    "#     # Combine results\n",
    "#     if all_sentiments:\n",
    "#         # Calculate overall sentiment\n",
    "#         sentiment_counts = {'POSITIVE': 0, 'NEGATIVE': 0, 'NEUTRAL': 0, 'MIXED': 0}\n",
    "#         total_scores = {'Positive': 0.0, 'Negative': 0.0, 'Neutral': 0.0, 'Mixed': 0.0}\n",
    "        \n",
    "#         for result in all_sentiments:\n",
    "#             sentiment_counts[result['sentiment']] += 1\n",
    "#             for key, value in result['scores'].items():\n",
    "#                 total_scores[key] += value\n",
    "        \n",
    "#         # Calculate averages\n",
    "#         num_chunks = len(all_sentiments)\n",
    "#         avg_scores = {key: value/num_chunks for key, value in total_scores.items()}\n",
    "#         overall_sentiment = max(sentiment_counts.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "#         # Get unique key phrases\n",
    "#         unique_phrases = list(dict.fromkeys(all_key_phrases))\n",
    "        \n",
    "#         return {\n",
    "#             'status': 'success',\n",
    "#             'overall_sentiment': overall_sentiment,\n",
    "#             'sentiment_scores': avg_scores,\n",
    "#             'key_phrases': unique_phrases[:10],  # Top 10 key phrases\n",
    "#             'chunks_processed': len(chunks)\n",
    "#         }\n",
    "    \n",
    "#     return {\n",
    "#         'status': 'error',\n",
    "#         'message': 'No results generated'\n",
    "#     }\n",
    "\n",
    "# def generate_summary_text(analysis_result: Dict) -> str:\n",
    "#     \"\"\"\n",
    "#     Generate readable summary from analysis results\n",
    "#     \"\"\"\n",
    "#     if analysis_result['status'] != 'success':\n",
    "#         return \"Could not generate summary.\"\n",
    "    \n",
    "#     summary = []\n",
    "    \n",
    "#     # Add sentiment information\n",
    "#     summary.append(f\"Overall Sentiment: {analysis_result['overall_sentiment']}\")\n",
    "#     summary.append(\"\\nSentiment Scores:\")\n",
    "#     for sentiment, score in analysis_result['sentiment_scores'].items():\n",
    "#         summary.append(f\"- {sentiment}: {score:.2%}\")\n",
    "    \n",
    "#     # Add key phrases\n",
    "#     summary.append(\"\\nKey Points:\")\n",
    "#     for phrase in analysis_result['key_phrases']:\n",
    "#         summary.append(f\"- {phrase}\")\n",
    "\n",
    "#     print(analysis_result)\n",
    "#     print(\"********\")\n",
    "    \n",
    "#     return '\\n'.join(summary)\n",
    "\n",
    "# # Get analysis results\n",
    "# print(\"Analyzing text...\")\n",
    "# results = summarize_text(transcibed_text)\n",
    "\n",
    "# # Generate and print summary\n",
    "# print(\"\\nSummary:\")\n",
    "# print(generate_summary_text(results))\n",
    "\n",
    "# # Print processing statistics\n",
    "# print(f\"\\nProcessed {results.get('chunks_processed', 0)} chunks of text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_runtime = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name=default_cfgs.get(\"aws_default_region\", \"\"),\n",
    "    aws_access_key_id=default_cfgs.get(\"aws_access_key_id\", \"\"),\n",
    "    aws_secret_access_key=default_cfgs.get(\"aws_secret_access_key\", \"\"),\n",
    "    aws_session_token=default_cfgs.get(\"aws_session_token\", \"\")\n",
    ")\n",
    "\n",
    "system_prompt = \"Give a text of transcribed text of a video, generate a concise summary of 80-120 words. \\\n",
    "Ensure to not miss out on any important points. \\\n",
    "The input text can be in any language, and the summary has to be returned in the same language. \\\n",
    "Return the response containing only the summary.\"\n",
    "\n",
    "payload = {\n",
    "    \"modelId\": \"anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "    \"body\": {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 4000,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": transalated_text.get('TranslatedText')\n",
    "                }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"system\": system_prompt\n",
    "    }\n",
    "}\n",
    "# print(kwargs)\n",
    "\n",
    "response = bedrock_runtime.invoke_model(\n",
    "        modelId=payload[\"modelId\"],\n",
    "        body=json.dumps(payload[\"body\"]).encode('utf-8')\n",
    "    )\n",
    "response_body = json.loads(response.get('body').read())\n",
    "response_body"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
